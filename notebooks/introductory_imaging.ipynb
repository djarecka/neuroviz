{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Python for visualizing neuroimaging data\n",
    "\n",
    "The primary goal of this workshop is to become familiar with loading, modifying, saving, and visualizing neuroimages in Python. A secondary goal is to develop a conceptual understanding of the data structures involved, to facilitate diagnosing problems in data or analysis pipelines.\n",
    "\n",
    "To these ends, we'll be exploring two libraries: [nibabel](http://nipy.org/nibabel/) and [nilearn](https://nilearn.github.io/).\n",
    "\n",
    "Each of these projects has excellent documentation. While this should get you started, it is well worth your time to look through these sites.\n",
    "\n",
    "From [1](https://nbviewer.jupyter.org/github/nipy/workshops/blob/master/170327-nipype/notebooks/nibabel_nilearn/nibabel_nilearn.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import nilearn as nl\n",
    "\n",
    "# Image settings\n",
    "import nilearn.plotting\n",
    "import matplotlib as mpl\n",
    "import pylab as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "%matplotlib inline\n",
    "mpl.rcParams['font.family'] = 'DejaVu Sans'\n",
    "\n",
    "out_dir = '/tmp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to confirm we're all on the same page, your versions should be the same as mine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Python version:\", sys.version.split()[0])\n",
    "print(\"nibabel version: {} (Commit: {})\".format(nib.__version__, open(os.path.join(os.path.dirname(nib.__file__), 'COMMIT_INFO.txt')).readlines()[1].split()[2]))\n",
    "print(\"nilearn version:\", nilearn.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nibabel\n",
    "\n",
    "Nibabel is a low-level Python library that gives access to a variety of imaging formats, with a particular focus on providing a common interface to the various volumetric formats produced by scanners and used in common neuroimaging toolkits.\n",
    "\n",
    " - NIfTI-1\n",
    " - NIfTI-2\n",
    " - SPM Analyze\n",
    " - FreeSurfer .mgh/.mgz files\n",
    " - Philips PAR/REC\n",
    " - Siemens ECAT\n",
    " - DICOM (limited support)\n",
    "\n",
    "It also supports surface file formats\n",
    "\n",
    " - GIFTI\n",
    " - FreeSurfer surfaces, labels and annotations\n",
    "\n",
    "Connectivity\n",
    "\n",
    " - CIFTI-2 (next release! but included in this container)\n",
    "\n",
    "Tractocgraphy\n",
    "\n",
    " - TrackViz .trk files\n",
    "\n",
    "And a number of related formats.\n",
    "\n",
    "*Almost* all of these can be loaded through the `nibabel.load` interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and inspecting images in nibabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = nib.load('/data/ds000114/sub-01/ses-test/anat/sub-01_ses-test_T1w.nii.gz')\n",
    "print(t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data-affine-header structure is common to volumetric formats in nibabel, though the details of the header will vary from format to format.\n",
    "\n",
    "These objects can be accessed through the following interfaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = t1.get_data()\n",
    "affine = t1.affine\n",
    "header = t1.header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Aside\n",
    "Why not just `t1.data`? Working with neuroimages can use a lot of memory, so nibabel works hard to be memory efficient. If it can read some data while leaving the rest on disk, it will. `t1.get_data()` reflects that it's doing some work behind the scenes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "The data is a simple numpy array. It has a shape, it can be sliced and generally manipulated as you would any array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "fig = plt.imshow(data[:, :, data.shape[2] // 2].T, cmap='Greys_r')\n",
    "fig.axes.set_xticks([])\n",
    "_ = fig.axes.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "## Exercise 1:\n",
    "\n",
    "Load the T1 data from subject 2. Plot the image using the same volume indexing as was done for subject 1. Also print the shape of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "t1_2 = nib.load('/data/ds000114/sub-02/ses-test/anat/sub-02_ses-test_T1w.nii.gz')\n",
    "data_2 = t1_2.get_data()\n",
    "fig = plt.imshow(data_2[:, :, data_2.shape[2] // 2].T, cmap='Greys_r')\n",
    "fig.axes.set_xticks([])\n",
    "_ = fig.axes.set_yticks([])\n",
    "print(data_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work on solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nibabel has its own viewer, which can be accessed through `img.orthoview()`. This viewer scales voxels to reflect their size, and labels orientations. From a normal IPython console, it will create an interactive window, and you can click to select different slices, similar to `mricron`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1.orthoview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Quirk\n",
    "\n",
    " - `img.get_data_dtype()` shows the type of the data on disk\n",
    " - `img.get_data().dtype` shows the type of the data that you're working with\n",
    "\n",
    "These are not always the same, and not being clear on this [has caused problems](https://github.com/nipy/nibabel/issues/490). Further, modifying one does not update the other. This is especially important to keep in mind later, when saving files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((data.dtype, t1.get_data_dtype()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Warning\n",
    "\n",
    "`img.orthoview()` may not work properly on OS X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affine\n",
    "\n",
    "The affine is a 4 x 4 numpy array. This describes the transformation from the voxel space (indices [i, j, k]) to the reference space (distance in mm (x, y, z)).\n",
    "\n",
    "It can be used, for instance, to discover the voxel that contains the origin of the image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z, _ = np.linalg.pinv(affine).dot(np.array([0, 0, 0, 1])).astype(int)\n",
    "\n",
    "print(\"Affine:\")\n",
    "print(affine)\n",
    "print\n",
    "print(\"Center: ({:d}, {:d}, {:d})\".format(x, y, z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The affine also encodes the axis orientation and voxel sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nib.aff2axcodes(affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nib.affines.voxel_sizes(affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "## Exercise 2:\n",
    "\n",
    "For subject 2:\n",
    "\n",
    "- Determine the center voxel \n",
    "- Determine axis orientation\n",
    "- Print voxel sizes\n",
    "- Display using orthoview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "t1_2 = nib.load('/data/ds000114/sub-02/ses-test/anat/sub-02_ses-test_T1w.nii.gz')\n",
    "affine_2 = t1_2.affine\n",
    "\n",
    "x, y, z, _ = np.linalg.pinv(affine_2).dot(np.array([0, 0, 0, 1])).astype(int)\n",
    "\n",
    "print(\"Affine:\")\n",
    "print(affine_2)\n",
    "print\n",
    "print(\"Center: ({:d}, {:d}, {:d})\".format(x, y, z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "nib.aff2axcodes(affine_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "nib.affines.voxel_sizes(affine_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "t1_2.orthoview()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine axis orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print voxel sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display using orthoview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Header\n",
    "\n",
    "The header is a nibabel structure that stores all of the metadata of the image. You can query it directly, if necessary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(header)\n",
    "print\n",
    "header.structarr['descrip']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But it also provides interfaces for the more common information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for method in ('get_zooms', 'get_xyzt_units', 'get_qform', 'get_sform'):\n",
    "    print(\"header.{}()\".format(method))\n",
    "    print(getattr(header, method)())\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally, we're not particularly interested in the header or the affine. But it's important to know they're there, and, especially, to remember to copy them when making new images, so that derivatives stay aligned with the original image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nib-ls\n",
    "\n",
    "Nibabel comes packaged with a command-line tool to print common metadata about any (volumetric) neuroimaging format nibabel supports. By default, it shows (on-disk) data type, dimensions and voxel sizes. We can also inspect header fields by name, for instance, `descrip`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nib-ls -H descrip /data/ds000114/sub-01/ses-test/anat/sub-01_ses-test_T1w.nii.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and saving images\n",
    "\n",
    "Suppose we want to save space by rescaling our image to a smaller datatype, such as an unsigned byte. To do this, we create a new image with a modified data array, and copy over the old affine and header. We then use the `img.to_filename()` method to save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaled = ((data - data.min()) * 255. / (data.max() - data.min())).astype(np.uint8)\n",
    "rescaled_img = nib.Nifti1Image(rescaled, affine=affine, header=header)\n",
    "\n",
    "print((rescaled_img.get_data().dtype, rescaled_img.get_data_dtype()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data array has the correct type, but the on-disk format is determined by the header, so saving now will not do what we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaled_img.to_filename(os.path.join(out_dir, 'rescaled1.nii.gz'))\n",
    "test = nib.load(os.path.join(out_dir, 'rescaled1.nii.gz'))\n",
    "print((test.get_data().dtype, test.get_data_dtype()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we need to set the data type in the header using `img.set_data_dtype()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaled_img.set_data_dtype(np.uint8)\n",
    "rescaled_img.to_filename(os.path.join(out_dir, 'rescaled2.nii.gz'))\n",
    "test = nib.load(os.path.join(out_dir, 'rescaled2.nii.gz'))\n",
    "print((test.get_data().dtype, test.get_data_dtype()))\n",
    "\n",
    "# Check that our data is what we think it is\n",
    "assert np.array_equal(test.get_data(), rescaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Aside\n",
    "\n",
    "There are other ways to save images. The advantage to `img.to_filename()` is that, if your file extension doesn't match the image type, it won't try anything fancy; it will just fail. In my experience, a mismatch of image and file extension is much more likely to be an error than what you intended."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional time series\n",
    "\n",
    "We've explored much of nibabel's functionality (at least for NIfTI-1 images). Let's take what we've learned to look at an fMRI series and create a mean volume that could be used for alignment.\n",
    "\n",
    "First we'll `nib-ls` the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nib-ls /data/ds000114/sub-01/ses-test/func/sub-01_ses-test_task-linebisection_bold.nii.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that this is a 4-dimensional dataset with 238 volumes, collected at a TR of 2.5s. We will confirm this when we load the file, and also see that the data is LAS oriented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi = nib.load('/data/ds000114/sub-01/ses-test/func/sub-01_ses-test_task-linebisection_bold.nii.gz')\n",
    "print(epi.get_data_dtype())\n",
    "print(epi.shape)\n",
    "print(epi.header.get_zooms())\n",
    "print(epi.header.get_xyzt_units())\n",
    "print(nib.aff2axcodes(epi.affine))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 4D images, `img.orthoview()` also shows the time series at the voxel in focus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi.orthoview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remembering that the data object is just a numpy array, we can easily take the mean over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_data = epi.get_data().mean(axis=3)\n",
    "mean_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_epi = nib.Nifti1Image(mean_data, affine=epi.affine, header=epi.header)\n",
    "mean_epi.orthoview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks how we'd expect. Let's save it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_epi.to_filename(os.path.join(out_dir, 'mean_epi.nii.gz'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "## Exercise 3: \n",
    "\n",
    "- Display the dimensions of each functional time series for sub-01\n",
    "- Plot the axial view of each mean image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "fl = sorted(glob('/data/ds000114/sub-01/ses-test/func/sub-01_ses-test_task-*bold.nii.gz'))\n",
    "fl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "fh, ax = plt.subplots(1, len(fl), figsize=(15, 5))\n",
    "for idx, filename in enumerate(fl):\n",
    "    img = nib.load(filename)\n",
    "    print(filename, img.shape)\n",
    "    ax[idx].imshow(img.get_data().mean(axis=3)[:, :, 15])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate list of functional tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over each file and print shape, calculate mean, and display using matplotlib subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review\n",
    "\n",
    "We've learned about nibabel, a low-level Python library for reading and writing common neuroimaging formats.\n",
    "\n",
    "Volumetric image formats are organized in a data-affine-header structure; the data is exposed as an n-dimensional numpy array, and the orientation of the data array is encoded in both the affine and the header.\n",
    "\n",
    "Images can be written using the `.to_filename()` method, and the on-disk data type can be adjusted with the `header.set_data_dtype()` method.\n",
    "\n",
    "Finally, we learned about `.orthoview()` and the `nib-ls` command-line program, for rapid inspection of data files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nilearn\n",
    "\n",
    "Nilearn is a library which makes visualizing neuroimages and exposing them to machine learning algorithms straightforward.\n",
    "\n",
    "It also simplifies a number of common tasks with neuroimages. For example, we can recreate the mean EPI image we just made in one line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nl.image.mean_img('/data/ds000114/sub-01/ses-test/func/sub-01_ses-test_task-linebisection_bold.nii.gz')\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nilearn images are just nibabel images! But notice that we didn't have to copy the affine or header. Nilearn does its best to keep your data and metadata together.\n",
    "\n",
    "Let's verify that both methods produced the same image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(mean_epi.get_data(), img.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array_equal(mean_epi.affine, img.affine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting images\n",
    "\n",
    "Nilearn has a variety of plotting facilities. `plot_epi` shows functional images in a high-contrast color scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl.plotting.plot_epi(mean_epi, cut_coords=(0, 0, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(nl.plotting.plot_epi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "## Exercise 4:\n",
    "\n",
    "Using the help output from above, redraw the mean_epi image as a set of 5 slices spanning front to back. Suppress the background using the `vmin` option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "nl.plotting.plot_epi(mean_epi, display_mode='y', cut_coords=5, vmin=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the mean_epi image slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot anatomical images. Let's show the FreeSurfer `aseg` segmentation over the T1 image we loaded earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl.plotting.plot_anat(t1, dim=-1, cut_coords=(0, 0, 0))\n",
    "nl.plotting.plot_roi('/data/ds000114/derivatives/freesurfer/sub-01/mri/aseg.mgz', t1,\n",
    "                     dim=-1, cut_coords=(0, 0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the overlay above looks misaligned. That's because this dataset uses a derived T1 image as input to `FreeSurfer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "## Exercise 5:\n",
    "\n",
    "The T1 image used for FreeSurfer is at `/data/ds000114/derivatives/fmriprep/sub-01/anat/sub-01_t1w_preproc.nii.gz`. Redraw the above plot using the correct background T1 image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "t1_correct = nib.load('/data/ds000114/derivatives/fmriprep/sub-01/anat/sub-01_t1w_preproc.nii.gz')\n",
    "nl.plotting.plot_anat(t1_correct, dim=-1, cut_coords=(0, 0, 0))\n",
    "nl.plotting.plot_roi('/data/ds000114/derivatives/freesurfer/sub-01/mri/aseg.mgz', t1_correct,\n",
    "                     dim=-1, cut_coords=(0, 0, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that nilearn will accept an image or a filename equally. Also recall that `t1` was a NIfTI-1 image, while `aseg` is in a FreeSurfer `.mgz` file. Nilearn takes advantage of the common interface (data-affine-header) that nibabel provides for these different formats, and makes correctly aligned overlays.\n",
    "\n",
    "This means we can use nilearn to verify alignment, for example when testing a new algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_algorithm(image):\n",
    "    # Just mess up the affine\n",
    "    bad_affine = image.affine.copy()\n",
    "    bad_affine[:, :2] = mask.affine[:, 1::-1]\n",
    "    return image.__class__(image.get_data(), bad_affine, mask.header)\n",
    "\n",
    "mask = nl.image.math_img(\"img > 0\", img='/data/ds000114/derivatives/freesurfer/sub-01/mri/brainmask.auto.mgz')\n",
    "new_mask = new_algorithm(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "## Exercise 6:\n",
    "\n",
    "Plot the original and messed up mask on the same background image with two colors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "t1_correct = nib.load('/data/ds000114/derivatives/fmriprep/sub-01/anat/sub-01_t1w_preproc.nii.gz')\n",
    "nl.plotting.plot_roi(mask, t1_correct, dim=-1, cut_coords=(0, 0, 0), cmap='Greens_r')\n",
    "nl.plotting.plot_roi(new_mask, t1_correct, dim=-1, cut_coords=(0, 0, 0), cmap='Reds_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nilearn can also plot results directly in MNI space using an outline. This uses the function `nl.plotting.plot_glass_brain`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nl.image.mean_img('/data/ds000114/derivatives/fmriprep/sub-01/ses-test/func/sub-01_ses-test_task-fingerfootlips_bold_space-mni152nlin2009casym_preproc.nii.gz')\n",
    "nl.plotting.plot_glass_brain(img, threshold=1000, colorbar=True, display_mode='lyrz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting surfaces\n",
    "\n",
    "Nilearn has recently added surface plotting to its repertoire. Let's examine the gray/white boundary and pial surfaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white = '/data/ds000114/derivatives/freesurfer/sub-01/surf/lh.white'\n",
    "pial = '/data/ds000114/derivatives/freesurfer/sub-01/surf/lh.pial'\n",
    "sulc = '/data/ds000114/derivatives/freesurfer/sub-01/surf/lh.sulc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = nl.plotting.plot_surf(white, bg_map=sulc)\n",
    "_ = nl.plotting.plot_surf(pial, bg_map=sulc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common step in surface pipelines is to create a surface halfway between the white and pial surface (often called the \"midthickness\" or \"graymid\" surface). The fastest, easiest, possibly wrong (but in practice fine) way to get this surface is to take the mean of the coordinates of the corresponding vertices on the white and pial surface. We can do this straightforwardly in nibabel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcoords, wfaces, wmeta = nib.freesurfer.read_geometry(white, read_metadata=True)\n",
    "pcoords, pfaces = nib.freesurfer.read_geometry(white, read_metadata=False)\n",
    "\n",
    "# Make sure these surfaces actually do correspond\n",
    "assert np.array_equal(wfaces, pfaces)\n",
    "\n",
    "(wcoords, wfaces, wmeta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that this is not an image object, just a tuple of coordinates, faces, and an optional metadata dictionary. And it's an example of a file nibabel doesn't handle with `nibabel.load()`.\n",
    "\n",
    "Coordinates are the (x, y, z) coordinates of each vertex; faces are a triangle composed of three vertices, and the metadata describes the provenance and alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcoords = (wcoords + pcoords) / 2\n",
    "# nilearn can be pretty picky about names, so fool it into reading this as a surface file\n",
    "graymid = os.path.join(out_dir, 'lh.white')\n",
    "nib.freesurfer.write_geometry(graymid, gcoords, wfaces, volume_info=wmeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = nl.plotting.plot_surf(graymid, bg_map=sulc, view='lateral')\n",
    "_ = nl.plotting.plot_surf(graymid, bg_map=sulc, view='medial')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks reasonable. Let's overlay it with the `aparc` parcellation. Nilearn doesn't handle these well yet, so again, we'll load with nibabel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aparc = nib.freesurfer.read_annot('/data/ds000114/derivatives/freesurfer/sub-01/label/lh.aparc.annot')\n",
    "\n",
    "_ = nl.plotting.plot_surf_roi(os.path.join(out_dir, 'lh.white'), aparc[0], bg_map=sulc, view='lateral')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "## Exercise 7:\n",
    "\n",
    "Plot the aparc overlay of the right hemisphere of subject 2 after calculating the mid-thickness geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "white = '/data/ds000114/derivatives/freesurfer/sub-02/surf/rh.white'\n",
    "pial = '/data/ds000114/derivatives/freesurfer/sub-02/surf/rh.pial'\n",
    "sulc = '/data/ds000114/derivatives/freesurfer/sub-02/surf/rh.sulc'\n",
    "\n",
    "wcoords, wfaces, wmeta = nib.freesurfer.read_geometry(white, read_metadata=True)\n",
    "pcoords, pfaces = nib.freesurfer.read_geometry(white, read_metadata=False)\n",
    "\n",
    "gcoords = (wcoords + pcoords) / 2\n",
    "# nilearn can be pretty picky about names, so fool it into reading this as a surface file\n",
    "graymid = os.path.join(out_dir, 'rh.white')\n",
    "nib.freesurfer.write_geometry(graymid, gcoords, wfaces, volume_info=wmeta)\n",
    "\n",
    "aparc = nib.freesurfer.read_annot('/data/ds000114/derivatives/freesurfer/sub-02/label/rh.aparc.annot')\n",
    "\n",
    "_ = nl.plotting.plot_surf_roi(os.path.join(out_dir, 'rh.white'), aparc[0], bg_map=sulc, view='lateral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point to data\n",
    "\n",
    "# Load data\n",
    "\n",
    "# Calculate mid thickness\n",
    "\n",
    "# Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review\n",
    "\n",
    "We've explored the visualization capabilities of nilearn, which include the ability to plot BOLD images, ROIs and masks overlaid on anatomical images and surfaces. Additionally, we've used nilearn's image manipulation utilities (`mean_img`, and `math_img`) to quickly create new, valid images, and considered the dangers of destroying your affine matrix. Finally, we created our own surface using nibabel's FreeSurfer utilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "In this tutorial, we've explored loading, saving and visualizing neuroimages, as well as how nibabel and nilearn can make some more sophisticated manipulations easy. At this point, you should be able to inspect and plot most images you encounter, as well as make modifications while preserving the alignment. If we've made it through the final section, you've also seen the basic workflow for performing a wide range of statistical analyses on BOLD time series in nilearn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
